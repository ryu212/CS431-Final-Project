{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":329006,"sourceType":"datasetVersion","datasetId":139630},{"sourceId":13798380,"sourceType":"datasetVersion","datasetId":8738954},{"sourceId":649055,"sourceType":"modelInstanceVersion","modelInstanceId":489630,"modelId":505033},{"sourceId":649099,"sourceType":"modelInstanceVersion","modelInstanceId":489665,"modelId":505067},{"sourceId":649102,"sourceType":"modelInstanceVersion","modelInstanceId":489667,"modelId":505069},{"sourceId":649106,"sourceType":"modelInstanceVersion","modelInstanceId":489669,"modelId":505071},{"sourceId":649113,"sourceType":"modelInstanceVersion","modelInstanceId":489675,"modelId":505077},{"sourceId":664986,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":503291,"modelId":518421}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:32:00.327698Z","iopub.execute_input":"2025-11-29T02:32:00.327950Z","iopub.status.idle":"2025-11-29T02:32:01.137298Z","shell.execute_reply.started":"2025-11-29T02:32:00.327923Z","shell.execute_reply":"2025-11-29T02:32:01.136581Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'stylegan2-ada-pytorch'...\nremote: Enumerating objects: 131, done.\u001b[K\nremote: Counting objects: 100% (2/2), done.\u001b[K\nremote: Compressing objects: 100% (2/2), done.\u001b[K\nremote: Total 131 (delta 0), reused 0 (delta 0), pack-reused 129 (from 2)\u001b[K\nReceiving objects: 100% (131/131), 1.13 MiB | 8.45 MiB/s, done.\nResolving deltas: 100% (57/57), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%cd stylegan2-ada-pytorch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:32:03.913426Z","iopub.execute_input":"2025-11-29T02:32:03.914269Z","iopub.status.idle":"2025-11-29T02:32:03.920767Z","shell.execute_reply.started":"2025-11-29T02:32:03.914236Z","shell.execute_reply":"2025-11-29T02:32:03.920038Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/stylegan2-ada-pytorch\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Tính FID","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/fashion-product-images-dataset/fashion-dataset/images","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tqdm import tqdm\nimport pandas as pd\n\ndf = pd.read_csv('/kaggle/input/fashion-dataset/val_fixed.csv',\n                 on_bad_lines='skip')\n\nsrc_dir = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/images\"\ndst_dir = \"/kaggle/working/val_images\"\nos.makedirs(dst_dir, exist_ok=True)\n\n# Lấy tất cả id trong CSV → dạng string\ncsv_ids = set(df[\"image\"].astype(str))\n\n# Map ảnh trong thư mục theo id\nfiles = []\nfor f in os.listdir(src_dir):\n    name = f \n    if name in csv_ids:\n        files.append(f)\n\nprint(\"Số ảnh match CSV:\", len(files))\n\ndef process(file):\n    try:\n        src_path = os.path.join(src_dir, file)\n        dst_path = os.path.join(dst_dir, file)\n        img = Image.open(src_path).convert(\"RGB\")\n        img = img.resize((256, 256), Image.LANCZOS)\n        img.save(dst_path)\n    except Exception as e:\n        print(f\"Error processing {file}: {e}\")\n\nwith ThreadPoolExecutor(max_workers=8) as executor:\n    list(tqdm(executor.map(process, files), total=len(files)))\n\nprint(\"Done!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:37:15.809293Z","iopub.execute_input":"2025-11-29T02:37:15.809795Z","iopub.status.idle":"2025-11-29T02:39:18.766061Z","shell.execute_reply.started":"2025-11-29T02:37:15.809759Z","shell.execute_reply":"2025-11-29T02:39:18.765217Z"}},"outputs":[{"name":"stdout","text":"Số ảnh match CSV: 4479\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4479/4479 [02:02<00:00, 36.48it/s]","output_type":"stream"},{"name":"stdout","text":"Done!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!mkdir /kaggle/working/models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:41:24.342339Z","iopub.execute_input":"2025-11-29T02:41:24.342717Z","iopub.status.idle":"2025-11-29T02:41:24.467291Z","shell.execute_reply.started":"2025-11-29T02:41:24.342686Z","shell.execute_reply":"2025-11-29T02:41:24.466229Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"!ls /kaggle/input/network-snapshot-004000-pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:40:48.911793Z","iopub.execute_input":"2025-11-29T02:40:48.912616Z","iopub.status.idle":"2025-11-29T02:40:49.036599Z","shell.execute_reply.started":"2025-11-29T02:40:48.912581Z","shell.execute_reply":"2025-11-29T02:40:49.035794Z"}},"outputs":[{"name":"stdout","text":"pytorch\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!cp /kaggle/input/stylegan2-700kimg/pytorch/default/1/network-snapshot-000700.pkl /kaggle/working/models/network-snapshot-700.pkl\n!cp /kaggle/input/stylegan2-1500kimg/pytorch/default/1/network-snapshot-001500-batch16.pkl /kaggle/working/models/network-snapshot-1500.pkl\n!cp /kaggle/input/stylegan2-2300kimg/pytorch/default/1/network-snapshot-002300-noada.pkl  /kaggle/working/models/network-snapshot-2300.pkl\n!cp /kaggle/input/stylegan2-3200kimg/pytorch/default/1/network-snapshot-003200.pkl       /kaggle/working/models/network-snapshot-3200.pkl\n!cp /kaggle/input/network-snapshot-004000-pkl/pytorch/default/1/network-snapshot-004000.pkl        /kaggle/working/models/network-snapshot-4000.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:42:10.146896Z","iopub.execute_input":"2025-11-29T02:42:10.147209Z","iopub.status.idle":"2025-11-29T02:42:20.114664Z","shell.execute_reply.started":"2025-11-29T02:42:10.147180Z","shell.execute_reply":"2025-11-29T02:42:20.113378Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!python dataset_tool.py --source=/kaggle/working/val_images --dest=./datasets/fashion_image.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:41:35.777275Z","iopub.execute_input":"2025-11-29T02:41:35.778193Z","iopub.status.idle":"2025-11-29T02:41:53.396813Z","shell.execute_reply.started":"2025-11-29T02:41:35.778147Z","shell.execute_reply":"2025-11-29T02:41:53.396010Z"}},"outputs":[{"name":"stdout","text":"  0%|                                                  | 0/4479 [00:00<?, ?it/s]/kaggle/working/stylegan2-ada-pytorch/dataset_tool.py:429: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n  img = PIL.Image.fromarray(img, { 1: 'L', 3: 'RGB' }[channels])\n100%|██████████████████████████████████████| 4479/4479 [00:16<00:00, 264.49it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!python calc_metrics.py --metrics=fid50k_full --data=./datasets/fashion_image.zip --mirror=1 \\\n    --network=/kaggle/working/models/network-snapshot-4000.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:43:02.766822Z","iopub.execute_input":"2025-11-29T02:43:02.767149Z","iopub.status.idle":"2025-11-29T02:54:41.695587Z","shell.execute_reply.started":"2025-11-29T02:43:02.767119Z","shell.execute_reply":"2025-11-29T02:54:41.694582Z"}},"outputs":[{"name":"stdout","text":"Loading network from \"/kaggle/working/models/network-snapshot-4000.pkl\"...\nDataset options:\n{\n  \"class_name\": \"training.dataset.ImageFolderDataset\",\n  \"path\": \"./datasets/fashion_image.zip\",\n  \"resolution\": 256,\n  \"use_labels\": false,\n  \"xflip\": true\n}\nLaunching processes...\nSetting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\nSetting up PyTorch plugin \"upfirdn2d_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\n\nGenerator             Parameters  Buffers  Output shape        Datatype\n---                   ---         ---      ---                 ---     \nmapping.fc0           262656      -        [1, 512]            float32 \nmapping.fc1           262656      -        [1, 512]            float32 \nmapping.fc2           262656      -        [1, 512]            float32 \nmapping.fc3           262656      -        [1, 512]            float32 \nmapping.fc4           262656      -        [1, 512]            float32 \nmapping.fc5           262656      -        [1, 512]            float32 \nmapping.fc6           262656      -        [1, 512]            float32 \nmapping.fc7           262656      -        [1, 512]            float32 \nmapping               -           512      [1, 14, 512]        float32 \nsynthesis.b4.conv1    2622465     32       [1, 512, 4, 4]      float32 \nsynthesis.b4.torgb    264195      -        [1, 3, 4, 4]        float32 \nsynthesis.b4:0        8192        16       [1, 512, 4, 4]      float32 \nsynthesis.b4:1        -           -        [1, 512, 4, 4]      float32 \nsynthesis.b8.conv0    2622465     80       [1, 512, 8, 8]      float32 \nsynthesis.b8.conv1    2622465     80       [1, 512, 8, 8]      float32 \nsynthesis.b8.torgb    264195      -        [1, 3, 8, 8]        float32 \nsynthesis.b8:0        -           16       [1, 512, 8, 8]      float32 \nsynthesis.b8:1        -           -        [1, 512, 8, 8]      float32 \nsynthesis.b16.conv0   2622465     272      [1, 512, 16, 16]    float32 \nsynthesis.b16.conv1   2622465     272      [1, 512, 16, 16]    float32 \nsynthesis.b16.torgb   264195      -        [1, 3, 16, 16]      float32 \nsynthesis.b16:0       -           16       [1, 512, 16, 16]    float32 \nsynthesis.b16:1       -           -        [1, 512, 16, 16]    float32 \nsynthesis.b32.conv0   2622465     1040     [1, 512, 32, 32]    float16 \nsynthesis.b32.conv1   2622465     1040     [1, 512, 32, 32]    float16 \nsynthesis.b32.torgb   264195      -        [1, 3, 32, 32]      float16 \nsynthesis.b32:0       -           16       [1, 512, 32, 32]    float16 \nsynthesis.b32:1       -           -        [1, 512, 32, 32]    float32 \nsynthesis.b64.conv0   1442561     4112     [1, 256, 64, 64]    float16 \nsynthesis.b64.conv1   721409      4112     [1, 256, 64, 64]    float16 \nsynthesis.b64.torgb   132099      -        [1, 3, 64, 64]      float16 \nsynthesis.b64:0       -           16       [1, 256, 64, 64]    float16 \nsynthesis.b64:1       -           -        [1, 256, 64, 64]    float32 \nsynthesis.b128.conv0  426369      16400    [1, 128, 128, 128]  float16 \nsynthesis.b128.conv1  213249      16400    [1, 128, 128, 128]  float16 \nsynthesis.b128.torgb  66051       -        [1, 3, 128, 128]    float16 \nsynthesis.b128:0      -           16       [1, 128, 128, 128]  float16 \nsynthesis.b128:1      -           -        [1, 128, 128, 128]  float32 \nsynthesis.b256.conv0  139457      65552    [1, 64, 256, 256]   float16 \nsynthesis.b256.conv1  69761       65552    [1, 64, 256, 256]   float16 \nsynthesis.b256.torgb  33027       -        [1, 3, 256, 256]    float16 \nsynthesis.b256:0      -           16       [1, 64, 256, 256]   float16 \nsynthesis.b256:1      -           -        [1, 64, 256, 256]   float32 \n---                   ---         ---      ---                 ---     \nTotal                 24767458    175568   -                   -       \n\nCalculating fid50k_full...\nDownloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/inception-2015-12-05.pt ... done\ndataset features    items 1024    time 23s          ms/item 22.45\ndataset features    items 2048    time 27s          ms/item 3.54\ndataset features    items 3072    time 30s          ms/item 3.54\ndataset features    items 4096    time 34s          ms/item 3.55\ndataset features    items 4479    time 38s          ms/item 10.52\ngenerator features  items 1024    time 13s          ms/item 12.45\ngenerator features  items 2048    time 24s          ms/item 11.13\ngenerator features  items 3072    time 36s          ms/item 11.29\ngenerator features  items 4096    time 47s          ms/item 11.45\ngenerator features  items 5120    time 59s          ms/item 11.62\ngenerator features  items 6144    time 1m 11s       ms/item 11.77\ngenerator features  items 7168    time 1m 24s       ms/item 12.00\ngenerator features  items 8192    time 1m 36s       ms/item 12.23\ngenerator features  items 9216    time 1m 49s       ms/item 12.37\ngenerator features  items 10240   time 2m 01s       ms/item 12.34\ngenerator features  items 11264   time 2m 14s       ms/item 12.17\ngenerator features  items 12288   time 2m 26s       ms/item 12.01\ngenerator features  items 13312   time 2m 39s       ms/item 12.02\ngenerator features  items 14336   time 2m 51s       ms/item 12.03\ngenerator features  items 15360   time 3m 03s       ms/item 12.11\ngenerator features  items 16384   time 3m 16s       ms/item 12.18\ngenerator features  items 17408   time 3m 28s       ms/item 12.18\ngenerator features  items 18432   time 3m 41s       ms/item 12.14\ngenerator features  items 19456   time 3m 53s       ms/item 12.11\ngenerator features  items 20480   time 4m 05s       ms/item 12.11\ngenerator features  items 21504   time 4m 18s       ms/item 12.12\ngenerator features  items 22528   time 4m 30s       ms/item 12.12\ngenerator features  items 23552   time 4m 43s       ms/item 12.10\ngenerator features  items 24576   time 4m 55s       ms/item 12.12\ngenerator features  items 25600   time 5m 07s       ms/item 12.12\ngenerator features  items 26624   time 5m 20s       ms/item 12.13\ngenerator features  items 27648   time 5m 32s       ms/item 12.15\ngenerator features  items 28672   time 5m 45s       ms/item 12.17\ngenerator features  items 29696   time 5m 57s       ms/item 12.16\ngenerator features  items 30720   time 6m 10s       ms/item 12.16\ngenerator features  items 31744   time 6m 22s       ms/item 12.14\ngenerator features  items 32768   time 6m 35s       ms/item 12.13\ngenerator features  items 33792   time 6m 47s       ms/item 12.13\ngenerator features  items 34816   time 6m 59s       ms/item 12.14\ngenerator features  items 35840   time 7m 12s       ms/item 12.14\ngenerator features  items 36864   time 7m 24s       ms/item 12.17\ngenerator features  items 37888   time 7m 37s       ms/item 12.15\ngenerator features  items 38912   time 7m 49s       ms/item 12.13\ngenerator features  items 39936   time 8m 02s       ms/item 12.16\ngenerator features  items 40960   time 8m 14s       ms/item 12.17\ngenerator features  items 41984   time 8m 27s       ms/item 12.16\ngenerator features  items 43008   time 8m 39s       ms/item 12.14\ngenerator features  items 44032   time 8m 51s       ms/item 12.15\ngenerator features  items 45056   time 9m 04s       ms/item 12.13\ngenerator features  items 46080   time 9m 16s       ms/item 12.18\ngenerator features  items 47104   time 9m 29s       ms/item 12.17\ngenerator features  items 48128   time 9m 41s       ms/item 12.16\ngenerator features  items 49152   time 9m 54s       ms/item 12.16\ngenerator features  items 50000   time 10m 05s      ms/item 12.84\n{\"results\": {\"fid50k_full\": 26.61480800860915}, \"metric\": \"fid50k_full\", \"total_time\": 648.3062326908112, \"total_time_str\": \"10m 48s\", \"num_gpus\": 1, \"snapshot_pkl\": \"/kaggle/working/models/network-snapshot-4000.pkl\", \"timestamp\": 1764384880.8038688}\n\nExiting...\n","output_type":"stream"}],"execution_count":20}]}